{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interaction Network\n",
    "\n",
    "This jupyter notebook is for implementing a paper [Interaction Networks for Learning about Objects, Relations and Physics](https://arxiv.org/abs/1612.00222) of [Deepmind](https://deepmind.com/). This code will be implemented by [Tensorflow](https://www.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Q\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters of the data\n",
    "Len_state = 6 # Length of the state\n",
    "Len_relation = 1 # Length of the relation \n",
    "Len_external = 1 # Length of the external effect\n",
    "Len_effect = 50 # Length of the effect\n",
    "Len_output = 4 # Length of the output (x position, y position, x velocity y velocity)\n",
    "\n",
    "Num_obj = 6 # Number of the objects \n",
    "Num_relation = 30 # Number of the relations\n",
    "\n",
    "B_shape = [(2*Len_state) + Len_relation, Num_relation]\n",
    "C_shape = [(Len_state + Len_external + Len_effect), Num_obj]\n",
    "\n",
    "# Parameter for training\n",
    "Num_batch = 512\n",
    "Num_epoch = 500\n",
    "Learning_rate = 0.001\n",
    "\n",
    "Is_train = True\n",
    "GPU_fraction = 0.3\n",
    "\n",
    "# Parameter for network\n",
    "fR_dense1 = [B_shape[0], 512]\n",
    "fR_dense2 = [512, 1024]\n",
    "fR_dense3 = [1024, Len_effect]\n",
    "\n",
    "fO_dense1 = [C_shape[0], 512]\n",
    "fO_dense2 = [512, 1024]\n",
    "fO_dense3 = [1024, Len_output]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_x shape: (1000000, 6, 6)\n",
      "Data_y shape: (1000000, 6, 6)\n",
      "TestData_x shape: (100000, 6, 6)\n",
      "TestData_y shape: (100000, 6, 6)\n"
     ]
    }
   ],
   "source": [
    "dataset_train = scipy.io.loadmat('./data/Training_dataset.mat')\n",
    "dataset_test  = scipy.io.loadmat('./data/Testing_dataset.mat')\n",
    "\n",
    "data_x = np.float32(dataset_train['X'])\n",
    "data_y = np.float32(dataset_train['Y'])\n",
    "\n",
    "data_x_test = dataset_test['X']\n",
    "data_y_test = dataset_test['Y']\n",
    "\n",
    "# data = np.concatenate([data_x, data_y], axis = 1)\n",
    "# np.random.shuffle(data)\n",
    "\n",
    "print(\"Data_x shape: \" + str(data_x.shape))\n",
    "print(\"Data_y shape: \" + str(data_y.shape))\n",
    "print(\"TestData_x shape: \" + str(data_x_test.shape))\n",
    "print(\"TestData_y shape: \" + str(data_y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights and bias \n",
    "def weight_variable(name, shape):\n",
    "    return tf.get_variable(name, shape = shape, initializer = tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "def bias_variable(name, shape):\n",
    "    return tf.get_variable(name, shape = shape, initializer = tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "O  = tf.placeholder(tf.float32, shape=[None, Len_state, Num_obj])\n",
    "Rr = tf.placeholder(tf.float32, shape=[None, Num_obj, Num_relation])\n",
    "Rs = tf.placeholder(tf.float32, shape=[None, Num_obj, Num_relation])\n",
    "Ra = tf.placeholder(tf.float32, shape=[None, Len_relation, Num_relation])\n",
    "X  = tf.placeholder(tf.float32, shape=[None, Len_external, Num_obj])\n",
    "\n",
    "# B -> input of the relation-centric function f_R\n",
    "B = tf.concat([tf.matmul(O,Rr),tf.matmul(O,Rs),Ra], axis = 1)\n",
    "\n",
    "# Define weight and bias of fR\n",
    "with tf.variable_scope('fR_'):\n",
    "    fR_w_fc1 = weight_variable('w_fc1', fR_dense1)\n",
    "    fR_w_fc2 = weight_variable('w_fc2', fR_dense2)\n",
    "    fR_w_fc3 = weight_variable('w_fc3', fR_dense3)\n",
    "\n",
    "    fR_b_fc1 = bias_variable('b_fc1', fR_dense1[1])\n",
    "    fR_b_fc2 = bias_variable('b_fc2', fR_dense2[1])\n",
    "    fR_b_fc3 = bias_variable('b_fc3', fR_dense3[1])\n",
    "\n",
    "#list of the effects\n",
    "e_list = []\n",
    "\n",
    "# fully connected for each column to obtain effect e\n",
    "for i in range(Num_relation):\n",
    "    b = tf.reshape(tf.slice(B,[0,0,i],[-1,-1,1]),[-1, B_shape[0]])\n",
    "\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(b, fR_w_fc1)+fR_b_fc1)\n",
    "    h_fc2 = tf.nn.relu(tf.matmul(h_fc1, fR_w_fc2)+fR_b_fc2)\n",
    "\n",
    "    e = tf.nn.relu(tf.matmul(h_fc2, fR_w_fc3)+fR_b_fc3)\n",
    "    e_list.append(e)\n",
    "\n",
    "# Effect Matrix E\n",
    "E = tf.stack(e_list, axis = 2)\n",
    "E_bar = tf.matmul(E, Rr, transpose_b = True)\n",
    "\n",
    "# C -> input of the object-centric function f_O\n",
    "C = tf.concat([O, X, E_bar], axis = 1)\n",
    "\n",
    "# Define weight and bias of fO\n",
    "with tf.variable_scope('fO_'):\n",
    "    fO_w_fc1 = weight_variable('w_fc1', fO_dense1)\n",
    "    fO_w_fc2 = weight_variable('w_fc2', fO_dense2)\n",
    "    fO_w_fc3 = weight_variable('w_fc3', fO_dense3)\n",
    "\n",
    "    fO_b_fc1 = bias_variable('b_fc1', fO_dense1[1])\n",
    "    fO_b_fc2 = bias_variable('b_fc2', fO_dense2[1])\n",
    "    fO_b_fc3 = bias_variable('b_fc3', fO_dense3[1])\n",
    "\n",
    "#list of the outputs\n",
    "p_list = []\n",
    "\n",
    "# fully connected for each column to obtain output p\n",
    "for i in range(Num_obj):\n",
    "    c = tf.reshape(tf.slice(C,[0,0,i],[-1,-1,1]),[-1, C_shape[0]])\n",
    "\n",
    "    fO_h_fc1 = tf.nn.relu(tf.matmul(c, fO_w_fc1)+fO_b_fc1)\n",
    "    fO_h_fc2 = tf.nn.relu(tf.matmul(fO_h_fc1, fO_w_fc2)+fO_b_fc2)\n",
    "\n",
    "    p = tf.nn.relu(tf.matmul(fO_h_fc2, fO_w_fc3)+fO_b_fc3)\n",
    "    p_list.append(p)\n",
    "\n",
    "# Output matrix P\n",
    "P = tf.stack(p_list, axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label (next state data)\n",
    "y = tf.placeholder(tf.float32, [None, Len_output, Num_obj])\n",
    "\n",
    "# Loss\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.reduce_mean(tf.square(y - P), axis = 2), axis = 1))\n",
    "\n",
    "# Training step\n",
    "train_step = tf.train.AdamOptimizer(learning_rate = Learning_rate, epsilon = 1e-02).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = GPU_fraction\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Load the file if the saved file exists\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "if Is_train == False:\n",
    "    # Restore variables from disk.\n",
    "    saver.restore(sess, \"./saved_network/model.ckpt\")\n",
    "    print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / Batch: 999936/1000000 / Loss: 0.55036837\n",
      "Epoch: 2 / Batch: 999936/1000000 / Loss: 0.57091445\n",
      "Epoch: 3 / Batch: 999936/1000000 / Loss: 0.59065205\n",
      "Epoch: 4 / Batch: 999936/1000000 / Loss: 0.58040714\n",
      "Epoch: 5 / Batch: 999936/1000000 / Loss: 0.58295023\n",
      "Epoch: 6 / Batch: 999936/1000000 / Loss: 0.5669404\n",
      "Epoch: 7 / Batch: 999936/1000000 / Loss: 0.5515185\n",
      "Epoch: 8 / Batch: 999936/1000000 / Loss: 0.5791697\n",
      "Epoch: 9 / Batch: 999936/1000000 / Loss: 0.54065186\n",
      "Epoch: 10 / Batch: 999936/1000000 / Loss: 0.56858593\n",
      "Epoch: 11 / Batch: 999936/1000000 / Loss: 0.52866524\n",
      "Batch: 386560/1000000\r"
     ]
    }
   ],
   "source": [
    "if Is_train == True:\n",
    "    train_data_num = data_x.shape[0]\n",
    "\n",
    "    for i in range(Num_epoch):\n",
    "        # Making batches\n",
    "        random_idx = np.arange(train_data_num)\n",
    "        np.random.shuffle(random_idx)\n",
    "        \n",
    "        batch_count = 1\n",
    "        num_batch_data = 0\n",
    "    \n",
    "        for j in range(0, train_data_num, Num_batch):\n",
    "            if j + Num_batch < train_data_num:\n",
    "                batch_index = [j, j + Num_batch]\n",
    "            else:\n",
    "                batch_index = [j, train_data_num-1]\n",
    "            \n",
    "            batch_x = data_x[random_idx[batch_index[0]:batch_index[-1]],:,:]\n",
    "            batch_y = data_y[random_idx[batch_index[0]:batch_index[-1]], 0:4, :]\n",
    "            \n",
    "            # Set relation and external -> every objects are each other's sender and receiver\n",
    "            batch_Rr = np.zeros([batch_index[1]-batch_index[0], Num_obj, Num_relation], dtype = np.float32)\n",
    "            batch_Rs = np.zeros([batch_index[1]-batch_index[0], Num_obj, Num_relation], dtype = np.float32)\n",
    "            batch_Ra = np.zeros([batch_index[1]-batch_index[0], Len_relation, Num_relation], dtype = np.float32)\n",
    "        \n",
    "            batch_external = np.zeros([batch_index[1]-batch_index[0], Len_external, Num_obj], dtype = np.float32)\n",
    "            \n",
    "            relation_idx = 0\n",
    "            for m in range(Num_obj):\n",
    "                for n in range(Num_obj):\n",
    "                    if m != n:\n",
    "                        batch_Rs[:,m,relation_idx] = 1\n",
    "                        batch_Rr[:,n,relation_idx] = 1\n",
    "                        \n",
    "                        relation_idx = relation_idx + 1         \n",
    "           \n",
    "            # Train\n",
    "            _, Loss_train = sess.run([train_step, loss], feed_dict={O: batch_x, Rr: batch_Rr, Rs: batch_Rs, Ra: batch_Ra, X: batch_external, y: batch_y})\n",
    "            \n",
    "            print(\"Batch: \" + str(j) + '/' + str(train_data_num), end=\"\\r\")\n",
    "    \n",
    "        # Print Progress\n",
    "        print(\"Epoch: \" + str(i+1) + ' / ' +\n",
    "              \"Loss: \" + str(Loss_train)) \n",
    "\n",
    "    save_path = saver.save(sess, 'saved_networks/model.ckpt')\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
