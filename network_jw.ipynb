{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import os\n",
    "\n",
    "# Initialize weights and bias \n",
    "def weight_variable(name, shape_in):\n",
    "    return tf.get_variable(name,shape=shape_in, initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "def bias_variable(name, shape_in):\n",
    "    return tf.get_variable(name,shape=shape_in, initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 6, 6) (500000, 6, 6)\n",
      "[0.66666667 1.         1.         1.24999998 0.8333333  0.        ]\n",
      "[0.66666667 1.         1.         1.24999998 0.8333333  0.        ]\n"
     ]
    }
   ],
   "source": [
    "data1 = scipy.io.loadmat('data/dataset.mat')\n",
    "data2 = scipy.io.loadmat('data/dataset2.mat')\n",
    "\n",
    "data_x = np.concatenate([data1['X'], data2['X']], axis = 0)\n",
    "data_y = np.concatenate([data1['Y'], data2['Y']], axis = 0)\n",
    "\n",
    "normalization_factor = [1.0/5, 1.0/5, 1.0/20, 1.0/20, 1.0, 1.0]\n",
    "normalization_bias = [0.0, 0, 0, 0, 0, 0]\n",
    "\n",
    "data_x[:,4,:] = 1/data_x[:,4,:]\n",
    "data_y[:,4,:] = 1/data_y[:,4,:]\n",
    "data_x[:,5,:] = 1/data_x[:,5,:]\n",
    "data_y[:,5,:] = 1/data_y[:,5,:]\n",
    "data_x[:,4,5] = 0\n",
    "data_y[:,4,5] = 0\n",
    "data_x[:,5,5] = 0\n",
    "data_y[:,5,5] = 0\n",
    "\n",
    "for i in range(len(normalization_factor)):\n",
    "    data_x[:,i,:] = data_x[:,i,:] * normalization_factor[i] + normalization_bias[i]\n",
    "    data_y[:,i,:] = data_y[:,i,:] * normalization_factor[i] + normalization_bias[i]\n",
    "\n",
    "print(np.shape(data_x), np.shape(data_y))\n",
    "\n",
    "print(data_x[0,5,:])\n",
    "print(data_y[0,5,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def interaction_net(O,Rr,Rs,Ra,X, output_len):\n",
    "\n",
    "    object_state = O.get_shape()[-2]\n",
    "    object_num = O.get_shape()[-1]\n",
    "    \n",
    "    relation_num = Rr.get_shape()[-1]\n",
    "    \n",
    "    B = tf.concat([tf.matmul(O,Rr),tf.matmul(O,Rs),Ra], axis = 1)\n",
    "    \n",
    "    B_len = B.get_shape()[-2]\n",
    "\n",
    "    print(O.get_shape())\n",
    "    print(Rr.get_shape())\n",
    "    print(B.get_shape())\n",
    "    \n",
    "    fR_hidden_num = 100\n",
    "    fR_hidden_layer = 3\n",
    "    \n",
    "    fR_weight = [weight_variable('fR_w_h'+str(i), [fR_hidden_num, fR_hidden_num]) for i in range(fR_hidden_layer-1)]\n",
    "    fR_weight.insert(0, weight_variable('fR_w_input', [B_len, fR_hidden_num]))\n",
    "    fR_bias = [bias_variable('fR_b_h'+str(i), [fR_hidden_num]) for i in range(fR_hidden_layer-1)]\n",
    "    fR_bias.insert(0, bias_variable('fR_b_input',[fR_hidden_num]))\n",
    "    \n",
    "    e_list = []\n",
    "    \n",
    "    for i in range(relation_num):\n",
    "        temp_B = tf.reshape(tf.slice(B,[0,0,i],[-1,-1,1]),[-1, B_len])\n",
    "        for layer in range(fR_hidden_layer):\n",
    "            if layer == 0:\n",
    "                fR_hidden_state = tf.nn.relu(tf.matmul(temp_B, fR_weight[layer]) + fR_bias[layer])\n",
    "            else:\n",
    "                fR_hidden_state = tf.nn.relu(tf.matmul(fR_hidden_state, fR_weight[layer]) + fR_bias[layer])\n",
    "        \n",
    "        e_list.append(fR_hidden_state)\n",
    "        \n",
    "    E = tf.stack(e_list, axis = 2)\n",
    "    E_bar = tf.matmul(E, Rr, transpose_b = True)\n",
    "    \n",
    "    print(E.get_shape())\n",
    "    print(E_bar.get_shape())\n",
    "    \n",
    "    C = tf.concat([O, X, E_bar], axis = 1)\n",
    "    \n",
    "    C_len = C.get_shape()[-2]\n",
    "    \n",
    "    print(C.get_shape())\n",
    "    \n",
    "    fO_hidden_num = 150\n",
    "    fO_hidden_layer = 3\n",
    "    \n",
    "    fO_weight = [weight_variable('fO_w_h'+str(i), [fO_hidden_num, fO_hidden_num]) for i in range(fO_hidden_layer-1)]\n",
    "    fO_weight.insert(0, weight_variable('fO_w_input', [C_len, fO_hidden_num]))\n",
    "    fO_bias = [bias_variable('fO_b_h'+str(i), [fO_hidden_num]) for i in range(fO_hidden_layer-1)]\n",
    "    fO_bias.insert(0, bias_variable('fO_b_input',[fO_hidden_num]))\n",
    "    \n",
    "    output_weight = weight_variable('out_w', [fO_hidden_num, output_len])\n",
    "    output_bias = weight_variable('out_b', [output_len])\n",
    "    \n",
    "    out_list = []\n",
    "    \n",
    "    for i in range(object_num):\n",
    "        temp_C = tf.reshape(tf.slice(C,[0,0,i],[-1,-1,1]),[-1, C_len])\n",
    "        for layer in range(fO_hidden_layer):\n",
    "            if layer == 0:\n",
    "                fO_hidden_state = tf.nn.relu(tf.matmul(temp_C, fO_weight[layer]) + fO_bias[layer])\n",
    "            else:\n",
    "                fO_hidden_state = tf.nn.relu(tf.matmul(fO_hidden_state, fO_weight[layer]) + fO_bias[layer])\n",
    "                \n",
    "        temp_out = tf.matmul(fO_hidden_state, output_weight) + output_bias\n",
    "        out_list.append(temp_out)\n",
    "    \n",
    "    output = tf.stack(out_list, axis = 2)\n",
    "    \n",
    "    print(output)        \n",
    "    \n",
    "    return output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 6, 6)\n",
      "(?, 6, 30)\n",
      "(?, 13, 30)\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "(?, 100, 30)\n",
      "(?, 100, 6)\n",
      "(?, 107, 6)\n",
      "Tensor(\"stack_1:0\", shape=(?, 4, 6), dtype=float32)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "object_state = np.shape(data_x)[-2]\n",
    "object_num = np.shape(data_x)[-1]\n",
    "# object_num = 1\n",
    "\n",
    "relation_num = 30\n",
    "relation_state = 1\n",
    "\n",
    "external_state = 1\n",
    "\n",
    "object_input = tf.placeholder(tf.float32, [None, object_state, object_num])\n",
    "relation_r = tf.placeholder(tf.float32, [None, object_num, relation_num])\n",
    "relation_s = tf.placeholder(tf.float32, [None, object_num, relation_num])\n",
    "relation_a = tf.placeholder(tf.float32, [None, relation_state, relation_num])\n",
    "external = tf.placeholder(tf.float32, [None, external_state, object_num])\n",
    "\n",
    "loss_state_num = 4\n",
    "\n",
    "y = tf.placeholder(tf.float32, [None, loss_state_num, object_num])\n",
    "\n",
    "predictions = interaction_net(object_input,relation_r,relation_s,relation_a,external, output_len = loss_state_num)\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_mean(tf.reduce_mean(tf.square(y - predictions), axis = 1), axis = 1)) + 1\n",
    "\n",
    "print(loss.get_shape())\n",
    "\n",
    "lr = tf.placeholder(tf.float32)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10, [============================= ] loss = 1.00088\n",
      "epoch 1/10, loss= 1.0019\n",
      "epoch 2/10, [============================= ] loss = 1.00062\n",
      "epoch 2/10, loss= 1.0016\n",
      "epoch 3/10, [============================= ] loss = 1.00048\n",
      "epoch 3/10, loss= 1.0013\n",
      "epoch 4/10, [============================= ] loss = 1.00039\n",
      "epoch 4/10, loss= 1.00113\n",
      "epoch 5/10, [============================= ] loss = 1.00014\n",
      "epoch 5/10, loss= 1.00109\n",
      "epoch 6/10, [============================= ] loss = 1.00334\n",
      "epoch 6/10, loss= 1.00107\n",
      "epoch 7/10, [============================= ] loss = 1.00008\n",
      "epoch 7/10, loss= 1.00103\n",
      "epoch 8/10, [============================= ] loss = 1.00013\n",
      "epoch 8/10, loss= 1.00105\n",
      "epoch 9/10, [============================= ] loss = 1.00418\n",
      "epoch 9/10, loss= 1.00098\n",
      "epoch 10/10, [============================= ] loss = 1.00073\n",
      "epoch 10/10, loss= 1.00093\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size = 256\n",
    "epoch_num = 10\n",
    "\n",
    "train_data_num = np.shape(data_x)[0]\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    order = np.arange(train_data_num)\n",
    "    np.random.shuffle(order)\n",
    "    temp_train_x = data_x[order]\n",
    "    temp_train_y = data_y[order]\n",
    "    for batch_step in range(int(train_data_num/batch_size)+1):\n",
    "        batch_idx = [batch_step*batch_size, (batch_step+1)*batch_size]\n",
    "        if batch_idx[1] > train_data_num: batch_idx[1] = train_data_num\n",
    "        \n",
    "        batch_x = temp_train_x[batch_idx[0]:batch_idx[1]]\n",
    "        batch_y = temp_train_y[batch_idx[0]:batch_idx[1]]\n",
    "        batch_y = batch_y[:,0:loss_state_num,:]\n",
    "        \n",
    "        batch_Rr = np.zeros([batch_idx[1]-batch_idx[0], object_num, relation_num])\n",
    "        batch_Rs = np.zeros([batch_idx[1]-batch_idx[0], object_num, relation_num])\n",
    "        batch_Ra = np.zeros([batch_idx[1]-batch_idx[0], relation_state, relation_num])\n",
    "        \n",
    "        batch_external = np.zeros([batch_idx[1]-batch_idx[0], external_state, object_num])\n",
    "        \n",
    "        relation_idx = 0\n",
    "        for i in range(object_num):\n",
    "            for j in range(object_num):\n",
    "                if i is not j:\n",
    "                    batch_Rs[:,i,relation_idx] = 1\n",
    "                    batch_Rr[:,j,relation_idx] = 1\n",
    "                    relation_idx = relation_idx + 1\n",
    "                    \n",
    "        train_step.run(feed_dict={object_input: batch_x, y: batch_y, relation_r: batch_Rr, relation_s: batch_Rs, relation_a: batch_Ra, external: batch_external, lr: 0.0001})\n",
    "        loss_value = loss.eval(feed_dict={object_input: batch_x, y: batch_y, relation_r: batch_Rr, relation_s: batch_Rs, relation_a: batch_Ra, external: batch_external})\n",
    "        print_num = int((batch_step/(int(train_data_num/batch_size)+1))*30)\n",
    "        print_string = \"epoch %d/%d, [\"%(epoch+1,epoch_num)+\"=\"*print_num+\" \"*(30-print_num) +\"] loss = \"+\"%g\"%(loss_value)\n",
    "        print(print_string, end=\"\\r\")\n",
    "        \n",
    "    \n",
    "    sample = 2048\n",
    "    temp_loss=np.zeros([int(train_data_num/sample)+1])\n",
    "    for batch_step in range(int(train_data_num/sample)+1):\n",
    "        batch_idx = [batch_step*sample, (batch_step+1)*sample]\n",
    "        if batch_idx[1] > train_data_num: batch_idx[1] = train_data_num\n",
    "            \n",
    "        batch_x = temp_train_x[batch_idx[0]:batch_idx[1]]\n",
    "        batch_y = temp_train_y[batch_idx[0]:batch_idx[1]]\n",
    "        batch_y = batch_y[:,0:loss_state_num,:]\n",
    "        \n",
    "        batch_Rr = np.zeros([batch_idx[1]-batch_idx[0], object_num, relation_num])\n",
    "        batch_Rs = np.zeros([batch_idx[1]-batch_idx[0], object_num, relation_num])\n",
    "        batch_Ra = np.zeros([batch_idx[1]-batch_idx[0], relation_state, relation_num])\n",
    "        \n",
    "        batch_external = np.zeros([batch_idx[1]-batch_idx[0], external_state, object_num])\n",
    "        \n",
    "        relation_idx = 0\n",
    "        for i in range(object_num):\n",
    "            for j in range(object_num):\n",
    "                if i is not j:\n",
    "                    batch_Rs[:,i,relation_idx] = 1\n",
    "                    batch_Rr[:,j,relation_idx] = 1\n",
    "                    relation_idx = relation_idx + 1\n",
    "        loss_value = loss.eval(feed_dict={object_input: batch_x, y: batch_y, relation_r: batch_Rr, relation_s: batch_Rs, relation_a: batch_Ra, external: batch_external})\n",
    "        temp_loss[batch_step] = loss_value * (batch_idx[1]-batch_idx[0])\n",
    "        # print(\"temp accuracy %g\"%temp_temp)\n",
    "    temp_loss = np.sum(temp_loss)/train_data_num\n",
    "    \n",
    "    print(\"\\nepoch %d/%d, loss= %g\"%(epoch+1, epoch_num, temp_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'fR_w_h0:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'fR_w_h1:0' shape=(100, 100) dtype=float32_ref>, <tf.Variable 'fR_w_input:0' shape=(13, 100) dtype=float32_ref>, <tf.Variable 'fR_b_h0:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'fR_b_h1:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'fR_b_input:0' shape=(100,) dtype=float32_ref>, <tf.Variable 'fO_w_h0:0' shape=(150, 150) dtype=float32_ref>, <tf.Variable 'fO_w_h1:0' shape=(150, 150) dtype=float32_ref>, <tf.Variable 'fO_w_input:0' shape=(107, 150) dtype=float32_ref>, <tf.Variable 'fO_b_h0:0' shape=(150,) dtype=float32_ref>, <tf.Variable 'fO_b_h1:0' shape=(150,) dtype=float32_ref>, <tf.Variable 'fO_b_input:0' shape=(150,) dtype=float32_ref>, <tf.Variable 'out_w:0' shape=(150, 4) dtype=float32_ref>, <tf.Variable 'out_b:0' shape=(4,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "print(tf.trainable_variables(scope=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMwsiYPDzMySODjMzCyJg8PMzJL8f4XUgP63hwHjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2771718e5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "test_idx = 50\n",
    "\n",
    "batch_x = data_x[test_idx:(test_idx+1)]\n",
    "batch_y = data_y[test_idx:(test_idx+1)]\n",
    "batch_y = batch_y[:,0:loss_state_num,:]\n",
    "\n",
    "batch_Rr = np.zeros([1, object_num, relation_num])\n",
    "batch_Rs = np.zeros([1, object_num, relation_num])\n",
    "batch_Ra = np.zeros([1, relation_state, relation_num])\n",
    "\n",
    "batch_external = np.zeros([1, external_state, object_num])\n",
    "\n",
    "relation_idx = 0\n",
    "for i in range(object_num):\n",
    "    for j in range(object_num):\n",
    "        if i is not j:\n",
    "            batch_Rs[:,i,relation_idx] = 1\n",
    "            batch_Rr[:,j,relation_idx] = 1\n",
    "            relation_idx = relation_idx + 1\n",
    "\n",
    "pred = predictions.eval(feed_dict={object_input: batch_x, y: batch_y, relation_r: batch_Rr, relation_s: batch_Rs, relation_a: batch_Ra, external: batch_external})\n",
    "# print(pred)\n",
    "plt.plot(data_x[test_idx,0,:], data_x[test_idx,1,:], 'go')\n",
    "plt.plot(data_y[test_idx,0,:], data_y[test_idx,1,:], 'ro')\n",
    "plt.plot(pred[0,0,:], pred[0,1,:], 'gx')\n",
    "plt.axis([-1, 1, -1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
