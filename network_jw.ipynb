{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import os\n",
    "\n",
    "# Initialize weights and bias \n",
    "def weight_variable(name, shape_in):\n",
    "    return tf.get_variable(name,shape=shape_in, initializer=tf.contrib.layers.xavier_initializer())\n",
    "\n",
    "def bias_variable(name, shape_in):\n",
    "    return tf.get_variable(name,shape=shape_in, initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500000, 6, 6) (500000, 6, 6)\n",
      "(100000, 6, 6) (100000, 6, 6)\n",
      "[0.66666667 1.         1.         1.24999998 0.8333333  0.        ]\n",
      "[0.66666667 1.         1.         1.24999998 0.8333333  0.        ]\n"
     ]
    }
   ],
   "source": [
    "data1 = scipy.io.loadmat('data/dataset.mat')\n",
    "data2 = scipy.io.loadmat('data/dataset2.mat')\n",
    "data_test = scipy.io.loadmat('data/dataset_test.mat')\n",
    "\n",
    "data_x = np.concatenate([data1['X'], data2['X']], axis = 0)\n",
    "data_y = np.concatenate([data1['Y'], data2['Y']], axis = 0)\n",
    "\n",
    "data_x_test = data_test['X']\n",
    "data_y_test = data_test['Y']\n",
    "\n",
    "normalization_factor = [1.0/5, 1.0/5, 1.0/20, 1.0/20, 1.0, 1.0]\n",
    "normalization_bias = [0.0, 0, 0, 0, 0, 0]\n",
    "\n",
    "data_x[:,4,:] = 1/data_x[:,4,:]\n",
    "data_y[:,4,:] = 1/data_y[:,4,:]\n",
    "data_x[:,5,:] = 1/data_x[:,5,:]\n",
    "data_y[:,5,:] = 1/data_y[:,5,:]\n",
    "data_x[:,4,5] = 0\n",
    "data_y[:,4,5] = 0\n",
    "data_x[:,5,5] = 0\n",
    "data_y[:,5,5] = 0\n",
    "\n",
    "data_x_test[:,4,:] = 1/data_x_test[:,4,:]\n",
    "data_y_test[:,4,:] = 1/data_y_test[:,4,:]\n",
    "data_x_test[:,5,:] = 1/data_x_test[:,5,:]\n",
    "data_y_test[:,5,:] = 1/data_y_test[:,5,:]\n",
    "data_x_test[:,4,5] = 0\n",
    "data_y_test[:,4,5] = 0\n",
    "data_x_test[:,5,5] = 0\n",
    "data_y_test[:,5,5] = 0\n",
    "\n",
    "for i in range(len(normalization_factor)):\n",
    "    data_x[:,i,:] = data_x[:,i,:] * normalization_factor[i] + normalization_bias[i]\n",
    "    data_y[:,i,:] = data_y[:,i,:] * normalization_factor[i] + normalization_bias[i]\n",
    "    \n",
    "    data_x_test[:,i,:] = data_x_test[:,i,:] * normalization_factor[i] + normalization_bias[i]\n",
    "    data_y_test[:,i,:] = data_y_test[:,i,:] * normalization_factor[i] + normalization_bias[i]\n",
    "\n",
    "print(np.shape(data_x), np.shape(data_y))\n",
    "print(np.shape(data_x_test), np.shape(data_y_test))\n",
    "\n",
    "print(data_x[0,5,:])\n",
    "print(data_y[0,5,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# interaction netwok 설계하는 부분, 입력은 논문에 있는 변수와 이름이 같음\n",
    "\n",
    "def interaction_net(O,Rr,Rs,Ra,X, output_len):\n",
    "\n",
    "    object_state = O.get_shape()[-2]\n",
    "    object_num = O.get_shape()[-1]\n",
    "    \n",
    "    relation_num = Rr.get_shape()[-1]\n",
    "    \n",
    "    B = tf.concat([tf.matmul(O,Rr),tf.matmul(O,Rs),Ra], axis = 1)\n",
    "    \n",
    "    B_len = B.get_shape()[-2]\n",
    "\n",
    "    print(O.get_shape())\n",
    "    print(Rr.get_shape())\n",
    "    print(B.get_shape())\n",
    "    \n",
    "# fR fully connected layer의 weight와 bias 정의하는 부분\n",
    "# hidden num = 1개의 layer 안에 있는 노드의 수\n",
    "# hidden_layer = hidden layer의 수\n",
    "\n",
    "    fR_hidden_num = 500\n",
    "    fR_hidden_layer = 3\n",
    "    \n",
    "    fR_weight = [weight_variable('fR_w_h'+str(i), [fR_hidden_num, fR_hidden_num]) for i in range(fR_hidden_layer-1)]\n",
    "    fR_weight.insert(0, weight_variable('fR_w_input', [B_len, fR_hidden_num]))\n",
    "    fR_bias = [bias_variable('fR_b_h'+str(i), [fR_hidden_num]) for i in range(fR_hidden_layer-1)]\n",
    "    fR_bias.insert(0, bias_variable('fR_b_input',[fR_hidden_num]))\n",
    "    \n",
    "    e_list = []\n",
    "    \n",
    "    for i in range(relation_num):\n",
    "        temp_B = tf.reshape(tf.slice(B,[0,0,i],[-1,-1,1]),[-1, B_len])\n",
    "        for layer in range(fR_hidden_layer):\n",
    "            if layer == 0:\n",
    "                fR_hidden_state = tf.nn.relu(tf.matmul(temp_B, fR_weight[layer]) + fR_bias[layer])\n",
    "            else:\n",
    "                fR_hidden_state = tf.nn.relu(tf.matmul(fR_hidden_state, fR_weight[layer]) + fR_bias[layer])\n",
    "        \n",
    "        e_list.append(fR_hidden_state)\n",
    "        \n",
    "    E = tf.stack(e_list, axis = 2)\n",
    "    E_bar = tf.matmul(E, Rr, transpose_b = True)\n",
    "    \n",
    "    print(E.get_shape())\n",
    "    print(E_bar.get_shape())\n",
    "    \n",
    "    C = tf.concat([O, X, E_bar], axis = 1)\n",
    "    \n",
    "    C_len = C.get_shape()[-2]\n",
    "    \n",
    "    print(C.get_shape())\n",
    "    \n",
    "# fO fully connected layer의 weight와 bias 정의하는 부분\n",
    "    \n",
    "    fO_hidden_num = 550\n",
    "    fO_hidden_layer = 3\n",
    "    \n",
    "    fO_weight = [weight_variable('fO_w_h'+str(i), [fO_hidden_num, fO_hidden_num]) for i in range(fO_hidden_layer-1)]\n",
    "    fO_weight.insert(0, weight_variable('fO_w_input', [C_len, fO_hidden_num]))\n",
    "    fO_bias = [bias_variable('fO_b_h'+str(i), [fO_hidden_num]) for i in range(fO_hidden_layer-1)]\n",
    "    fO_bias.insert(0, bias_variable('fO_b_input',[fO_hidden_num]))\n",
    "    \n",
    "    output_weight = weight_variable('out_w', [fO_hidden_num, output_len])\n",
    "    output_bias = weight_variable('out_b', [output_len])\n",
    "    \n",
    "    out_list = []\n",
    "    \n",
    "    for i in range(object_num):\n",
    "        temp_C = tf.reshape(tf.slice(C,[0,0,i],[-1,-1,1]),[-1, C_len])\n",
    "        for layer in range(fO_hidden_layer):\n",
    "            if layer == 0:\n",
    "                fO_hidden_state = tf.nn.relu(tf.matmul(temp_C, fO_weight[layer]) + fO_bias[layer])\n",
    "            else:\n",
    "                fO_hidden_state = tf.nn.relu(tf.matmul(fO_hidden_state, fO_weight[layer]) + fO_bias[layer])\n",
    "                \n",
    "        temp_out = tf.matmul(fO_hidden_state, output_weight) + output_bias\n",
    "        out_list.append(temp_out)\n",
    "    \n",
    "    output = tf.stack(out_list, axis = 2)\n",
    "    \n",
    "    print(output)        \n",
    "    \n",
    "    return output\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 6, 6)\n",
      "(?, 6, 30)\n",
      "(?, 13, 30)\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "(?, 500, 30)\n",
      "(?, 500, 6)\n",
      "(?, 507, 6)\n",
      "Tensor(\"stack_1:0\", shape=(?, 4, 6), dtype=float32)\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# 공튀기기 문제를 위한 전체 그래프를 설계하는 부분\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "object_state = np.shape(data_x)[-2]\n",
    "object_num = np.shape(data_x)[-1]\n",
    "# object_num = 1\n",
    "\n",
    "relation_num = 30\n",
    "relation_state = 1\n",
    "\n",
    "external_state = 1\n",
    "\n",
    "object_input = tf.placeholder(tf.float32, [None, object_state, object_num])\n",
    "relation_r = tf.placeholder(tf.float32, [None, object_num, relation_num])\n",
    "relation_s = tf.placeholder(tf.float32, [None, object_num, relation_num])\n",
    "relation_a = tf.placeholder(tf.float32, [None, relation_state, relation_num])\n",
    "external = tf.placeholder(tf.float32, [None, external_state, object_num])\n",
    "\n",
    "loss_state_num = 4\n",
    "\n",
    "y = tf.placeholder(tf.float32, [None, loss_state_num, object_num])\n",
    "\n",
    "predictions = interaction_net(object_input,relation_r,relation_s,relation_a,external, output_len = loss_state_num)\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_mean(tf.reduce_mean(tf.square(y - predictions), axis = 1), axis = 1))\n",
    "\n",
    "print(loss.get_shape())\n",
    "\n",
    "lr = tf.placeholder(tf.float32)\n",
    "\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/50, [============================= ] loss = 0.001673062\n",
      "epoch 1/50, test loss = 0.000751126\n",
      "epoch 2/50, [============================= ] loss = 0.000186067\n",
      "epoch 2/50, test loss = 0.000747691\n",
      "epoch 3/50, [============================= ] loss = 7.38582e-05\n",
      "epoch 3/50, test loss = 0.000748538\n",
      "epoch 4/50, [============================= ] loss = 9.30586e-05\n",
      "epoch 4/50, test loss = 0.000746208\n",
      "epoch 5/50, [============================= ] loss = 4.83505e-05\n",
      "epoch 5/50, test loss = 0.000744716\n",
      "epoch 6/50, [============================= ] loss = 0.000882819\n",
      "epoch 6/50, test loss = 0.0007436\n",
      "epoch 7/50, [============================= ] loss = 0.000444978\n",
      "epoch 7/50, test loss = 0.000746178\n",
      "epoch 8/50, [============================= ] loss = 0.000784109\n",
      "epoch 8/50, test loss = 0.000748344\n",
      "epoch 9/50, [============================= ] loss = 3.57449e-05\n",
      "epoch 9/50, test loss = 0.000745778\n",
      "epoch 10/50, [============================= ] loss = 0.000576165\n",
      "epoch 10/50, test loss = 0.000743129\n",
      "epoch 11/50, [============================= ] loss = 0.000441652\n",
      "epoch 11/50, test loss = 0.00074268\n",
      "epoch 12/50, [============================= ] loss = 0.000861249\n",
      "epoch 12/50, test loss = 0.000743006\n",
      "epoch 13/50, [============================= ] loss = 0.000239443\n",
      "epoch 13/50, test loss = 0.000742099\n",
      "epoch 14/50, [============================= ] loss = 0.000830233\n",
      "epoch 14/50, test loss = 0.000740524\n",
      "epoch 15/50, [============================= ] loss = 0.000375223\n",
      "epoch 15/50, test loss = 0.00074272\n",
      "epoch 16/50, [============================= ] loss = 0.000217056\n",
      "epoch 16/50, test loss = 0.000740396\n",
      "epoch 17/50, [============================= ] loss = 0.001550577\n",
      "epoch 17/50, test loss = 0.00074115\n",
      "epoch 18/50, [============================= ] loss = 0.000130662\n",
      "epoch 18/50, test loss = 0.000740802\n",
      "epoch 19/50, [============================= ] loss = 0.000531774\n",
      "epoch 19/50, test loss = 0.000739634\n",
      "epoch 20/50, [============================= ] loss = 0.000478523\n",
      "epoch 20/50, test loss = 0.000738202\n",
      "epoch 21/50, [============================= ] loss = 0.003321986\n",
      "epoch 21/50, test loss = 0.000737338\n",
      "epoch 22/50, [============================= ] loss = 3.85521e-05\n",
      "epoch 22/50, test loss = 0.000737954\n",
      "epoch 23/50, [============================= ] loss = 0.001482167\n",
      "epoch 23/50, test loss = 0.000737202\n",
      "epoch 24/50, [============================= ] loss = 0.000161936\n",
      "epoch 24/50, test loss = 0.000738849\n",
      "epoch 25/50, [============================= ] loss = 0.001424786\n",
      "epoch 25/50, test loss = 0.000736329\n",
      "epoch 26/50, [============================= ] loss = 0.001418245\n",
      "epoch 26/50, test loss = 0.000737739\n",
      "epoch 27/50, [============================= ] loss = 0.000816028\n",
      "epoch 27/50, test loss = 0.00073525\n",
      "epoch 28/50, [============================= ] loss = 0.001845678\n",
      "epoch 28/50, test loss = 0.000735816\n",
      "epoch 29/50, [============================= ] loss = 6.93295e-05\n",
      "epoch 29/50, test loss = 0.000735579\n",
      "epoch 30/50, [============================= ] loss = 0.001635226\n",
      "epoch 30/50, test loss = 0.00073451\n",
      "epoch 31/50, [============================= ] loss = 0.000784532\n",
      "epoch 31/50, test loss = 0.000734999\n",
      "epoch 32/50, [============================= ] loss = 0.000155773\n",
      "epoch 32/50, test loss = 0.000732796\n",
      "epoch 33/50, [============================= ] loss = 0.002012177\n",
      "epoch 33/50, test loss = 0.00073486\n",
      "epoch 34/50, [============================= ] loss = 0.000467743\n",
      "epoch 34/50, test loss = 0.00073199\n",
      "epoch 35/50, [============================= ] loss = 0.000476743\n",
      "epoch 35/50, test loss = 0.000732486\n",
      "epoch 36/50, [============================= ] loss = 0.000176734\n",
      "epoch 36/50, test loss = 0.000735914\n",
      "epoch 37/50, [============================= ] loss = 4.39487e-05\n",
      "epoch 37/50, test loss = 0.00073198\n",
      "epoch 38/50, [============================= ] loss = 0.002903815\n",
      "epoch 38/50, test loss = 0.000733043\n",
      "epoch 39/50, [============================= ] loss = 0.000122982\n",
      "epoch 39/50, test loss = 0.000732326\n",
      "epoch 40/50, [============================= ] loss = 8.72052e-05\n",
      "epoch 40/50, test loss = 0.000734459\n",
      "epoch 41/50, [============================= ] loss = 0.000131564\n",
      "epoch 41/50, test loss = 0.000728603\n",
      "epoch 42/50, [============================= ] loss = 0.000619197\n",
      "epoch 42/50, test loss = 0.000728384\n",
      "epoch 43/50, [============================= ] loss = 4.60465e-05\n",
      "epoch 43/50, test loss = 0.000733248\n",
      "epoch 44/50, [============================= ] loss = 0.002558188\n",
      "epoch 44/50, test loss = 0.000734332\n",
      "epoch 45/50, [============================= ] loss = 3.22511e-05\n",
      "epoch 45/50, test loss = 0.000727979\n",
      "epoch 46/50, [============================= ] loss = 0.000591138\n",
      "epoch 46/50, test loss = 0.000729682\n",
      "epoch 47/50, [============================= ] loss = 0.001580558\n",
      "epoch 47/50, test loss = 0.000729143\n",
      "epoch 48/50, [============================= ] loss = 0.000343371\n",
      "epoch 48/50, test loss = 0.00072638\n",
      "epoch 49/50, [============================= ] loss = 0.000597525\n",
      "epoch 49/50, test loss = 0.000729492\n",
      "epoch 50/50, [============================= ] loss = 8.22309e-05\n",
      "epoch 50/50, test loss = 0.000725853\n"
     ]
    }
   ],
   "source": [
    "# 학습 코드\n",
    "\n",
    "batch_size = 256\n",
    "epoch_num = 50\n",
    "\n",
    "train_data_num = np.shape(data_x)[0]\n",
    "test_data_num = np.shape(data_x_test)[0]\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    order = np.arange(train_data_num)\n",
    "    np.random.shuffle(order)\n",
    "    temp_train_x = data_x[order]\n",
    "    temp_train_y = data_y[order]\n",
    "    for batch_step in range(int(train_data_num/batch_size)+1):\n",
    "        batch_idx = [batch_step*batch_size, (batch_step+1)*batch_size]\n",
    "        if batch_idx[1] > train_data_num: batch_idx[1] = train_data_num\n",
    "        \n",
    "        batch_x = temp_train_x[batch_idx[0]:batch_idx[1]]\n",
    "        batch_y = temp_train_y[batch_idx[0]:batch_idx[1]]\n",
    "        batch_y = batch_y[:,0:loss_state_num,:]\n",
    "        \n",
    "        batch_Rr = np.zeros([batch_idx[1]-batch_idx[0], object_num, relation_num])\n",
    "        batch_Rs = np.zeros([batch_idx[1]-batch_idx[0], object_num, relation_num])\n",
    "        batch_Ra = np.zeros([batch_idx[1]-batch_idx[0], relation_state, relation_num])\n",
    "        \n",
    "        batch_external = np.zeros([batch_idx[1]-batch_idx[0], external_state, object_num])\n",
    "        \n",
    "        relation_idx = 0\n",
    "        for i in range(object_num):\n",
    "            for j in range(object_num):\n",
    "                if i is not j:\n",
    "                    batch_Rs[:,i,relation_idx] = 1\n",
    "                    batch_Rr[:,j,relation_idx] = 1\n",
    "                    relation_idx = relation_idx + 1\n",
    "                    \n",
    "        train_step.run(feed_dict={object_input: batch_x, y: batch_y, relation_r: batch_Rr, relation_s: batch_Rs, relation_a: batch_Ra, external: batch_external, lr: 0.000001})\n",
    "        loss_value = loss.eval(feed_dict={object_input: batch_x, y: batch_y, relation_r: batch_Rr, relation_s: batch_Rs, relation_a: batch_Ra, external: batch_external})\n",
    "        print_num = int((batch_step/(int(train_data_num/batch_size)+1))*30)\n",
    "        print_string = \"epoch %d/%d, [\"%(epoch+1,epoch_num)+\"=\"*print_num+\" \"*(30-print_num) +\"] loss = \"+\"%g\"%(loss_value)\n",
    "        print(print_string, end=\"\\r\")\n",
    "        \n",
    "# test loss 계산하는 부분 (sample 갯수 만큼씩 나눠서 계산)\n",
    "\n",
    "    sample = 2048\n",
    "    temp_loss=np.zeros([int(test_data_num/sample)+1])\n",
    "    for batch_step in range(int(test_data_num/sample)+1):\n",
    "        batch_idx = [batch_step*sample, (batch_step+1)*sample]\n",
    "        if batch_idx[1] > test_data_num: batch_idx[1] = test_data_num\n",
    "            \n",
    "        batch_x = data_x_test[batch_idx[0]:batch_idx[1]]\n",
    "        batch_y = data_y_test[batch_idx[0]:batch_idx[1]]\n",
    "        batch_y = batch_y[:,0:loss_state_num,:]\n",
    "        \n",
    "        batch_Rr = np.zeros([batch_idx[1]-batch_idx[0], object_num, relation_num])\n",
    "        batch_Rs = np.zeros([batch_idx[1]-batch_idx[0], object_num, relation_num])\n",
    "        batch_Ra = np.zeros([batch_idx[1]-batch_idx[0], relation_state, relation_num])\n",
    "        \n",
    "        batch_external = np.zeros([batch_idx[1]-batch_idx[0], external_state, object_num])\n",
    "        \n",
    "        relation_idx = 0\n",
    "        for i in range(object_num):\n",
    "            for j in range(object_num):\n",
    "                if i is not j:\n",
    "                    batch_Rs[:,i,relation_idx] = 1\n",
    "                    batch_Rr[:,j,relation_idx] = 1\n",
    "                    relation_idx = relation_idx + 1\n",
    "        loss_value = loss.eval(feed_dict={object_input: batch_x, y: batch_y, relation_r: batch_Rr, relation_s: batch_Rs, relation_a: batch_Ra, external: batch_external})\n",
    "        temp_loss[batch_step] = loss_value * (batch_idx[1]-batch_idx[0])\n",
    "\n",
    "    temp_loss = np.sum(temp_loss)/test_data_num\n",
    "    \n",
    "    print(\"\\nepoch %d/%d, test loss = %g\"%(epoch+1, epoch_num, temp_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'fR_w_h0:0' shape=(500, 500) dtype=float32_ref>, <tf.Variable 'fR_w_h1:0' shape=(500, 500) dtype=float32_ref>, <tf.Variable 'fR_w_input:0' shape=(13, 500) dtype=float32_ref>, <tf.Variable 'fR_b_h0:0' shape=(500,) dtype=float32_ref>, <tf.Variable 'fR_b_h1:0' shape=(500,) dtype=float32_ref>, <tf.Variable 'fR_b_input:0' shape=(500,) dtype=float32_ref>, <tf.Variable 'fO_w_h0:0' shape=(550, 550) dtype=float32_ref>, <tf.Variable 'fO_w_h1:0' shape=(550, 550) dtype=float32_ref>, <tf.Variable 'fO_w_input:0' shape=(507, 550) dtype=float32_ref>, <tf.Variable 'fO_b_h0:0' shape=(550,) dtype=float32_ref>, <tf.Variable 'fO_b_h1:0' shape=(550,) dtype=float32_ref>, <tf.Variable 'fO_b_input:0' shape=(550,) dtype=float32_ref>, <tf.Variable 'out_w:0' shape=(550, 4) dtype=float32_ref>, <tf.Variable 'out_b:0' shape=(4,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "print(tf.trainable_variables(scope=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wEVxMJnaynbuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2334fae0f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "test_idx = 5\n",
    "\n",
    "batch_x = data_x_test[test_idx:(test_idx+1)]\n",
    "batch_y = data_y_test[test_idx:(test_idx+1)]\n",
    "batch_y = batch_y[:,0:loss_state_num,:]\n",
    "\n",
    "batch_Rr = np.zeros([1, object_num, relation_num])\n",
    "batch_Rs = np.zeros([1, object_num, relation_num])\n",
    "batch_Ra = np.zeros([1, relation_state, relation_num])\n",
    "\n",
    "batch_external = np.zeros([1, external_state, object_num])\n",
    "\n",
    "relation_idx = 0\n",
    "for i in range(object_num):\n",
    "    for j in range(object_num):\n",
    "        if i is not j:\n",
    "            batch_Rs[:,i,relation_idx] = 1\n",
    "            batch_Rr[:,j,relation_idx] = 1\n",
    "            relation_idx = relation_idx + 1\n",
    "\n",
    "pred = predictions.eval(feed_dict={object_input: batch_x, relation_r: batch_Rr, relation_s: batch_Rs, relation_a: batch_Ra, external: batch_external})\n",
    "# print(pred)\n",
    "plt.plot(data_x_test[test_idx,0,:], data_x_test[test_idx,1,:], 'go')\n",
    "plt.plot(data_y_test[test_idx,0,:], data_y_test[test_idx,1,:], 'ro')\n",
    "plt.plot(pred[0,0,:], pred[0,1,:], 'gx')\n",
    "plt.axis([-1, 1, -1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1, 4, 6)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npESJQ0REUqLEISIiKVHiEBGRlPx/Ls6vE5xsnNwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2335114c0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# recursive prediction을 하는 부분\n",
    "\n",
    "plt.figure(1)\n",
    "test_idx = 1100\n",
    "test_step = 10\n",
    "\n",
    "batch_x = data_x_test[test_idx:(test_idx+1)]\n",
    "batch_y = data_y_test[test_idx:(test_idx+1)]\n",
    "batch_y = batch_y[:,0:loss_state_num,:]\n",
    "\n",
    "batch_Rr = np.zeros([1, object_num, relation_num])\n",
    "batch_Rs = np.zeros([1, object_num, relation_num])\n",
    "batch_Ra = np.zeros([1, relation_state, relation_num])\n",
    "\n",
    "batch_external = np.zeros([1, external_state, object_num])\n",
    "\n",
    "relation_idx = 0\n",
    "prediction_list = []\n",
    "input_data  = np.copy(batch_x)\n",
    "for i in range(object_num):\n",
    "    for j in range(object_num):\n",
    "        if i is not j:\n",
    "            batch_Rs[:,i,relation_idx] = 1\n",
    "            batch_Rr[:,j,relation_idx] = 1\n",
    "            relation_idx = relation_idx + 1\n",
    "for i in range(test_step):\n",
    "    pred = predictions.eval(feed_dict={object_input: input_data, relation_r: batch_Rr, relation_s: batch_Rs, relation_a: batch_Ra, external: batch_external})\n",
    "    prediction_list.append(pred)\n",
    "    input_data = np.copy(batch_x)\n",
    "    input_data[:,0:loss_state_num,:] = pred\n",
    "    \n",
    "recursive_prediction = np.asarray(prediction_list)\n",
    "print(np.shape(recursive_prediction))\n",
    "    \n",
    "# print(pred)\n",
    "plt.plot(data_x_test[test_idx,0,:], data_x_test[test_idx,1,:], 'ko')\n",
    "plt.plot(data_y_test[test_idx:(test_idx+test_step),0,:], data_y_test[test_idx:(test_idx+test_step),1,:], 'ro')\n",
    "plt.plot(recursive_prediction[:,0,0,:], recursive_prediction[:,0,1,:], 'gx')\n",
    "plt.axis([-1, 1, -1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
